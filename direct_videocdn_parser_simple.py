"""
ç®€åŒ–ç‰ˆç›´æ¥è§£æ videocdn.ihelpy.net - ç›´æ¥è°ƒç”¨API
è·³è¿‡å¯èƒ½è¢«403æ‹¦æˆªçš„æ­¥éª¤ï¼Œç›´æ¥è°ƒç”¨å·²çŸ¥çš„APIç«¯ç‚¹
"""

import requests
import json
import re
import gzip
import zlib
from typing import Optional, List, Dict

# å°è¯•å¯¼å…¥brotli
try:
    import brotli
    HAS_BROTLI = True
except ImportError:
    HAS_BROTLI = False
    print("âš ï¸ è­¦å‘Š: æœªå®‰è£…brotliåº“ï¼Œæ— æ³•è§£å‹Brotliå‹ç¼©çš„å“åº”")
    print("ğŸ’¡ å®‰è£…æ–¹æ³•: pip install brotli")


class DirectVideoCdnParserSimple:
    """ç®€åŒ–ç‰ˆç›´æ¥è§£æå™¨ - ç›´æ¥è°ƒç”¨API"""
    
    def __init__(self):
        self.session = requests.Session()
        # æ³¨æ„ï¼šç§»é™¤Accept-Encodingæ¥é¿å…å‹ç¼©ï¼Œè®©æœåŠ¡å™¨è¿”å›æœªå‹ç¼©çš„å“åº”
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8,ja;q=0.7',
            # 'Accept-Encoding': 'gzip, deflate, br',  # ç§»é™¤ï¼Œé¿å…å‹ç¼©
            'Connection': 'keep-alive',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache',
            'Referer': 'https://m1-z2.cloud.nnpp.vip:2223/',
            'Origin': 'https://m1-z2.cloud.nnpp.vip:2223',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-site',
            'Sec-Fetch-Storage-Access': 'active',
            'sec-ch-ua': '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"',
        })
    
    def load_params_from_file(self) -> Optional[Dict]:
        """ä»æ•è·çš„å‚æ•°æ–‡ä»¶ä¸­åŠ è½½å‚æ•°"""
        try:
            with open('captured_api_params.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
                if data.get('captured_params'):
                    # è¿”å›æœ€æ–°çš„å‚æ•°
                    latest = data['captured_params'][-1]
                    return {
                        'z': latest.get('z'),
                        's1ig': latest.get('s1ig'),
                        'g': latest.get('g')
                    }
        except FileNotFoundError:
            pass
        except Exception as e:
            print(f"   âš ï¸ åŠ è½½å‚æ•°æ–‡ä»¶å¤±è´¥: {e}")
        return None
    
    def get_z_param_from_api_service(self, video_url: str, api_url: str = None) -> Optional[str]:
        """ä»APIæœåŠ¡è·å–zå‚æ•°ï¼ˆæœåŠ¡å™¨ç«¯æ–¹æ¡ˆï¼‰"""
        if api_url is None:
            api_url = "http://localhost:5000/api/get_z_param"
        
        try:
            response = requests.get(api_url, params={'video_url': video_url}, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if data.get('success') and data.get('z_param'):
                    return data['z_param']
        except Exception as e:
            print(f"   âš ï¸ ä»APIæœåŠ¡è·å–zå‚æ•°å¤±è´¥: {e}")
        return None
    
    def get_z_param_from_website(self, video_url: str) -> Optional[str]:
        """ç›´æ¥ä»è§£æç½‘ç«™æå–zå‚æ•°ï¼ˆæ— éœ€æµè§ˆå™¨ï¼‰"""
        try:
            parser_url = f"https://videocdn.ihelpy.net/jiexi/m1907.html?m1907jx={video_url}"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            }
            
            response = self.session.get(parser_url, headers=headers, timeout=30)
            
            if response.status_code == 200:
                html = response.text
                
                # ä»APIè°ƒç”¨URLä¸­æå–zå‚æ•°
                import re
                api_url_pattern = r'https://[^/]+/api/v/\?[^"\'<>]*z=([a-f0-9]{32})'
                matches = re.findall(api_url_pattern, html, re.IGNORECASE)
                if matches:
                    return matches[0]
        except Exception as e:
            print(f"   âš ï¸ ä»ç½‘ç«™æå–zå‚æ•°å¤±è´¥: {e}")
        return None
    
    def construct_api_url(self, video_url: str, g_param: str = None, 
                          z_value: str = None, s1ig_value: str = None) -> str:
        """æ„é€ API URL"""
        print(f"\n[æ­¥éª¤1] æ„é€ API URL...")
        
        # åŸºäºåˆ†æç»“æœï¼ŒAPI URLæ ¼å¼ä¸ºï¼š
        # https://m1-a1.cloud.nnpp.vip:2223/api/v/?z={z}&jx={video_url}&s1ig={s1ig}&g={g}
        
        # å°è¯•ä»æ–‡ä»¶åŠ è½½å‚æ•°
        file_params = self.load_params_from_file()
        if file_params:
            print(f"   ğŸ’¡ ä» captured_api_params.json åŠ è½½å‚æ•°")
            if not z_value:
                z_value = file_params.get('z')
            if not s1ig_value:
                s1ig_value = file_params.get('s1ig')
            if not g_param:
                g_param = file_params.get('g')
        
        # å¦‚æœzå‚æ•°ä»æœªè®¾ç½®ï¼Œå°è¯•ä»ç½‘ç«™æå–ï¼ˆæœåŠ¡å™¨ç«¯æ–¹æ¡ˆï¼‰
        if not z_value:
            print(f"   ğŸ’¡ å°è¯•ä»è§£æç½‘ç«™æå–zå‚æ•°...")
            z_value = self.get_z_param_from_website(video_url)
            if z_value:
                print(f"   âœ… æˆåŠŸä»ç½‘ç«™æå–zå‚æ•°: {z_value[:16]}...")
        
        # å¦‚æœä»æœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆå¯èƒ½å·²è¿‡æœŸï¼‰
        if not z_value:
            z_value = "b413af76b43b1a0abc231718862417e2"  # æœ€æ–°æ•è·çš„å‚æ•°
        if not s1ig_value:
            s1ig_value = "11397"  # æœ€æ–°æ•è·çš„å‚æ•°
        
        # gå‚æ•°ï¼šä»æœ€æ–°æ•è·ä¸­å‘ç°å¯èƒ½æ˜¯ç©ºå­—ç¬¦ä¸²ï¼Œå¯èƒ½æ˜¯å¯é€‰çš„
        # å¦‚æœæœªè®¾ç½®ï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²ï¼ˆä»æœ€æ–°æ•è·ä¸­å‘ç°ï¼‰
        if g_param is None:
            g_param = ""  # æœ€æ–°æ•è·ä¸­gå‚æ•°ä¸ºç©ºå­—ç¬¦ä¸²
        
        api_url = f"https://m1-a1.cloud.nnpp.vip:2223/api/v/?z={z_value}&jx={video_url}&s1ig={s1ig_value}&g={g_param}"
        
        print(f"   âœ… API URL: {api_url}")
        print(f"   ğŸ’¡ æ³¨æ„: zã€s1igå’Œgå‚æ•°å¯èƒ½éœ€è¦åŠ¨æ€ç”Ÿæˆ")
        print(f"   ğŸ’¡ gå‚æ•°å½“å‰å€¼: {g_param}")
        
        return api_url
    
    def call_api(self, api_url: str) -> Optional[Dict]:
        """è°ƒç”¨APIè·å–è§†é¢‘ä¿¡æ¯"""
        print(f"\n[æ­¥éª¤2] è°ƒç”¨API...")
        print(f"   URL: {api_url}")
        
        try:
            # æ–¹æ³•1: å°è¯•ä¸å‹ç¼©ï¼ˆç§»é™¤Accept-Encodingï¼‰
            headers_no_compress = self.session.headers.copy()
            if 'Accept-Encoding' in headers_no_compress:
                del headers_no_compress['Accept-Encoding']
            
            response = self.session.get(api_url, headers=headers_no_compress, timeout=30, allow_redirects=True)
            
            print(f"   çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code != 200:
                print(f"   âš ï¸ APIè¿”å›é200çŠ¶æ€ç ")
                return None
            
            content_type = response.headers.get('Content-Type', '').lower()
            content_encoding = response.headers.get('Content-Encoding', '').lower()
            print(f"   Content-Type: {content_type}")
            print(f"   Content-Encoding: {content_encoding or 'none'}")
            
            # è·å–åŸå§‹å­—èŠ‚æ•°æ®
            raw_content = response.content
            print(f"   åŸå§‹å“åº”é•¿åº¦: {len(raw_content)} å­—èŠ‚")
            
            # å°è¯•è§£å‹
            content = None
            decompress_success = False
            
            if content_encoding == 'gzip':
                try:
                    content = gzip.decompress(raw_content).decode('utf-8')
                    print(f"   âœ… Gzipè§£å‹æˆåŠŸ")
                    decompress_success = True
                except Exception as e:
                    print(f"   âš ï¸ Gzipè§£å‹å¤±è´¥: {e}")
            elif content_encoding == 'deflate':
                try:
                    content = zlib.decompress(raw_content).decode('utf-8')
                    print(f"   âœ… Deflateè§£å‹æˆåŠŸ")
                    decompress_success = True
                except Exception as e:
                    print(f"   âš ï¸ Deflateè§£å‹å¤±è´¥: {e}")
            elif content_encoding == 'br':
                # Brotliå‹ç¼©
                if HAS_BROTLI:
                    try:
                        content = brotli.decompress(raw_content).decode('utf-8')
                        print(f"   âœ… Brotliè§£å‹æˆåŠŸ")
                        decompress_success = True
                    except Exception as e:
                        print(f"   âš ï¸ Brotliè§£å‹å¤±è´¥: {e}")
                        print(f"   ğŸ’¡ å°è¯•ç›´æ¥è§£ç ï¼ˆå¯èƒ½Content-Encodingå¤´é”™è¯¯ï¼‰...")
                else:
                    print(f"   âš ï¸ å“åº”æ ‡è®°ä¸ºBrotliå‹ç¼©ï¼Œä½†æœªå®‰è£…brotliåº“")
                    print(f"   ğŸ’¡ å°è¯•ç›´æ¥è§£ç ...")
            
            # å¦‚æœè§£å‹å¤±è´¥ï¼Œå°è¯•ç›´æ¥è§£ç ï¼ˆå¯èƒ½Content-Encodingå¤´é”™è¯¯ï¼‰
            if not decompress_success:
                try:
                    # å°è¯•ç›´æ¥UTF-8è§£ç 
                    test_content = raw_content.decode('utf-8')
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„JSONå¼€å¤´
                    if test_content.strip().startswith('{') or test_content.strip().startswith('['):
                        content = test_content
                        print(f"   âœ… ç›´æ¥UTF-8è§£ç æˆåŠŸï¼ˆContent-Encodingå¤´å¯èƒ½é”™è¯¯ï¼‰")
                    else:
                        # å°è¯•å…¶ä»–ç¼–ç 
                        raise UnicodeDecodeError('utf-8', raw_content, 0, 1, 'test')
                except (UnicodeDecodeError, UnicodeError):
                    # å°è¯•å…¶ä»–ç¼–ç 
                    for encoding in ['gbk', 'latin1', 'cp1252', 'iso-8859-1']:
                        try:
                            test_content = raw_content.decode(encoding, errors='ignore')
                            if test_content.strip().startswith('{') or test_content.strip().startswith('['):
                                content = test_content
                                print(f"   âœ… ä½¿ç”¨{encoding}ç¼–ç è§£ç æˆåŠŸ")
                                break
                        except:
                            continue
                    
                    # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹
                    if not content:
                        try:
                            import chardet
                            detected = chardet.detect(raw_content)
                            encoding = detected.get('encoding', 'utf-8')
                            content = raw_content.decode(encoding, errors='ignore')
                            print(f"   âœ… ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹ç¼–ç ({encoding})è§£ç æˆåŠŸ")
                        except ImportError:
                            # æœ€åå°è¯•ï¼šå¿½ç•¥é”™è¯¯
                            content = raw_content.decode('utf-8', errors='ignore')
                            print(f"   âš ï¸ ä½¿ç”¨UTF-8è§£ç ï¼ˆå¿½ç•¥é”™è¯¯ï¼‰")
            
            if not content:
                print(f"   âŒ æ— æ³•è§£ç å“åº”å†…å®¹")
                print(f"   åŸå§‹å­—èŠ‚é¢„è§ˆ: {raw_content[:200]}")
                # å³ä½¿è§£ç å¤±è´¥ï¼Œä¹Ÿå°è¯•ä»åŸå§‹å­—èŠ‚ä¸­æå–m3u8é“¾æ¥
                try:
                    raw_str = raw_content.decode('utf-8', errors='ignore')
                    if '.m3u8' in raw_str:
                        print(f"   ğŸ’¡ åœ¨åŸå§‹å­—èŠ‚ä¸­æ‰¾åˆ°m3u8å…³é”®å­—ï¼Œå°è¯•æå–...")
                        m3u8_patterns = [
                            r'https?://[^\s"\'<>]+\.m3u8[^\s"\'<>]*',
                            r'["\']([^"\']+\.m3u8[^"\']*)["\']',
                        ]
                        found_urls = []
                        for pattern in m3u8_patterns:
                            matches = re.findall(pattern, raw_str, re.IGNORECASE)
                            for match in matches:
                                url = match if isinstance(match, str) else match[0] if match else None
                                if url and url.startswith('http') and url not in found_urls:
                                    found_urls.append(url)
                                    print(f"   âœ… æ‰¾åˆ°m3u8é“¾æ¥: {url}")
                        if found_urls:
                            return {'m3u8_urls': found_urls}
                except:
                    pass
                return None
            
            print(f"   è§£ç åé•¿åº¦: {len(content)} å­—ç¬¦")
            print(f"   å†…å®¹é¢„è§ˆ: {content[:200]}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯ä¿¡æ¯
            if 'è”ç³»QQ' in content or 'è·å–jsonç‰ˆapiåœ°å€' in content:
                print(f"   âš ï¸ APIè¿”å›é”™è¯¯ä¿¡æ¯ï¼Œå‚æ•°å¯èƒ½å·²è¿‡æœŸ")
                print(f"   ğŸ’¡ å»ºè®®è¿è¡Œ: python3 capture_api_params.py é‡æ–°æ•è·å‚æ•°")
                return None
            
            # å°è¯•è§£æJSON
            try:
                json_data = json.loads(content)
                print(f"   âœ… JSONè§£ææˆåŠŸ")
                return json_data
            except json.JSONDecodeError as e:
                print(f"   âŒ JSONè§£æå¤±è´¥: {e}")
                print(f"   å®Œæ•´å“åº”å†…å®¹: {content[:1000]}")
                
                # å°è¯•ä»å“åº”ä¸­ç›´æ¥æå–m3u8é“¾æ¥ï¼ˆå³ä½¿ä¸æ˜¯JSONï¼‰
                m3u8_patterns = [
                    r'https?://[^\s"\'<>]+\.m3u8[^\s"\'<>]*',
                    r'["\']([^"\']+\.m3u8[^"\']*)["\']',
                ]
                found_urls = []
                for pattern in m3u8_patterns:
                    matches = re.findall(pattern, content, re.IGNORECASE)
                    for match in matches:
                        url = match if isinstance(match, str) else match[0] if match else None
                        if url and url.startswith('http') and url not in found_urls:
                            found_urls.append(url)
                            print(f"   âœ… ä»å“åº”ä¸­æå–åˆ°m3u8é“¾æ¥: {url}")
                
                if found_urls:
                    # æ„é€ ä¸€ä¸ªç®€å•çš„JSONç»“æ„è¿”å›
                    return {
                        'type': 'movie',
                        'data': [{
                            'source': {
                                'eps': [{'url': url} for url in found_urls]
                            }
                        }]
                    }
                
                return None
                
        except Exception as e:
            print(f"   âŒ è¯·æ±‚å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def extract_m3u8_urls(self, api_response: Dict) -> List[str]:
        """ä»APIå“åº”ä¸­æå–m3u8é“¾æ¥"""
        print(f"\n[æ­¥éª¤3] æå–m3u8é“¾æ¥...")
        
        m3u8_urls = []
        
        def find_m3u8_in_json(obj, path=""):
            """é€’å½’æŸ¥æ‰¾m3u8é“¾æ¥"""
            if isinstance(obj, dict):
                for key, value in obj.items():
                    find_m3u8_in_json(value, f"{path}.{key}")
            elif isinstance(obj, list):
                for i, item in enumerate(obj):
                    find_m3u8_in_json(item, f"{path}[{i}]")
            elif isinstance(obj, str):
                if '.m3u8' in obj and obj.startswith('http'):
                    if obj not in m3u8_urls:
                        m3u8_urls.append(obj)
                        print(f"   âœ… æ‰¾åˆ°m3u8é“¾æ¥ ({path}): {obj}")
        
        find_m3u8_in_json(api_response)
        
        if not m3u8_urls:
            print(f"   âš ï¸ æœªæ‰¾åˆ°m3u8é“¾æ¥")
            print(f"   ğŸ’¡ å°è¯•ä»å“åº”ä¸­æœç´¢...")
            # å¦‚æœé€’å½’æ²¡æ‰¾åˆ°ï¼Œå°è¯•æ­£åˆ™è¡¨è¾¾å¼
            json_str = json.dumps(api_response)
            m3u8_patterns = [
                r'https?://[^\s"\'<>]+\.m3u8[^\s"\'<>]*',
                r'["\']([^"\']+\.m3u8[^"\']*)["\']',
            ]
            for pattern in m3u8_patterns:
                matches = re.findall(pattern, json_str, re.IGNORECASE)
                for match in matches:
                    url = match if isinstance(match, str) else match[0] if match else None
                    if url and url.startswith('http') and url not in m3u8_urls:
                        m3u8_urls.append(url)
                        print(f"   âœ… é€šè¿‡æ­£åˆ™æ‰¾åˆ°m3u8é“¾æ¥: {url}")
        
        return m3u8_urls
    
    def get_best_m3u8(self, m3u8_urls: List[str]) -> Optional[str]:
        """é€‰æ‹©æœ€ä½³çš„m3u8é“¾æ¥"""
        print(f"\n[æ­¥éª¤4] é€‰æ‹©æœ€ä½³m3u8é“¾æ¥...")
        
        if not m3u8_urls:
            return None
        
        # ä¼˜å…ˆé€‰æ‹©ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯HDç‰ˆæœ¬ï¼‰
        best_url = m3u8_urls[0]
        print(f"   âœ… é€‰æ‹©: {best_url}")
        
        return best_url
    
    def verify_m3u8(self, m3u8_url: str) -> bool:
        """éªŒè¯m3u8é“¾æ¥æ˜¯å¦æœ‰æ•ˆ"""
        print(f"\n[æ­¥éª¤5] éªŒè¯m3u8é“¾æ¥...")
        print(f"   URL: {m3u8_url}")
        
        try:
            # ä½¿ç”¨ä¸åŒçš„è¯·æ±‚å¤´éªŒè¯
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': '*/*',
                'Referer': 'https://videocdn.ihelpy.net/',
            }
            
            response = requests.get(m3u8_url, headers=headers, timeout=10, stream=True)
            
            if response.status_code == 200:
                # è¯»å–å‰å‡ è¡Œ
                content = ''
                for i, line in enumerate(response.iter_lines(decode_unicode=True)):
                    if i >= 5:
                        break
                    if line:
                        content += str(line) + '\n'
                
                if content.strip().startswith('#EXTM3U'):
                    print(f"   âœ… m3u8é“¾æ¥æœ‰æ•ˆ")
                    print(f"   é¢„è§ˆ: {content[:200]}")
                    return True
                else:
                    print(f"   âš ï¸ m3u8é“¾æ¥æ ¼å¼å¯èƒ½ä¸æ­£ç¡®")
                    print(f"   å†…å®¹é¢„è§ˆ: {content[:200]}")
                    return False
            else:
                print(f"   âš ï¸ éªŒè¯è¯·æ±‚è¿”å›çŠ¶æ€ç : {response.status_code}")
                return True  # ä»ç„¶è¿”å›Trueï¼Œå› ä¸ºå¯èƒ½æ˜¯è®¿é—®é™åˆ¶é—®é¢˜
                
        except Exception as e:
            print(f"   âš ï¸ éªŒè¯å¤±è´¥: {e}")
            print(f"   ğŸ’¡ é“¾æ¥å¯èƒ½ä»ç„¶æœ‰æ•ˆï¼Œä½†éœ€è¦ç‰¹å®šè¯·æ±‚å¤´æˆ–Cookie")
            return True  # ä»ç„¶è¿”å›Trueï¼Œå› ä¸ºå¯èƒ½æ˜¯è®¿é—®é™åˆ¶é—®é¢˜
    
    def parse_video(self, video_url: str) -> Optional[str]:
        """è§£æè§†é¢‘ï¼Œè·å–æœ€ç»ˆm3u8"""
        print("=" * 60)
        print("ç®€åŒ–ç‰ˆç›´æ¥è§£æ videocdn.ihelpy.net")
        print("=" * 60)
        print(f"ç›®æ ‡è§†é¢‘: {video_url}")
        
        # æ­¥éª¤1: æ„é€ API URL
        api_url = self.construct_api_url(video_url)
        
        # æ­¥éª¤2: è°ƒç”¨API
        api_response = self.call_api(api_url)
        if not api_response:
            print("\nâŒ APIè°ƒç”¨å¤±è´¥")
            print("\nğŸ’¡ å¯èƒ½çš„åŸå› :")
            print("   1. zå‚æ•°éœ€è¦åŠ¨æ€ç”Ÿæˆ")
            print("   2. s1igå‚æ•°éœ€è¦åŠ¨æ€ç”Ÿæˆ")
            print("   3. éœ€è¦ç‰¹å®šçš„Refereræˆ–Cookie")
            print("   4. APIç«¯ç‚¹å·²å˜æ›´")
            print("\nğŸ’¡ å»ºè®®:")
            print("   1. ä½¿ç”¨æµè§ˆå™¨åˆ†æè„šæœ¬è·å–æœ€æ–°çš„APIå‚æ•°")
            print("   2. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            return None
        
        # æ­¥éª¤3: æå–m3u8é“¾æ¥
        m3u8_urls = self.extract_m3u8_urls(api_response)
        if not m3u8_urls:
            print("\nâŒ æœªèƒ½æå–m3u8é“¾æ¥")
            print(f"\nğŸ“„ APIå“åº”å†…å®¹:")
            print(json.dumps(api_response, indent=2, ensure_ascii=False)[:1000])
            return None
        
        # æ­¥éª¤4: é€‰æ‹©æœ€ä½³m3u8
        best_m3u8 = self.get_best_m3u8(m3u8_urls)
        if not best_m3u8:
            print("\nâŒ æœªèƒ½é€‰æ‹©m3u8é“¾æ¥")
            return None
        
        # æ­¥éª¤5: éªŒè¯m3u8ï¼ˆå¯é€‰ï¼‰
        self.verify_m3u8(best_m3u8)
        
        # ä¿å­˜ç»“æœ
        result = {
            'video_url': video_url,
            'api_url': api_url,
            'api_response': api_response,
            'm3u8_urls': m3u8_urls,
            'best_m3u8': best_m3u8,
        }
        
        with open('videocdn_parse_result.json', 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"\nâœ… å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: videocdn_parse_result.json")
        
        print("\n" + "=" * 60)
        print("âœ… è§£ææˆåŠŸï¼")
        print("=" * 60)
        print(f"\nğŸ¬ æ‰¾åˆ° {len(m3u8_urls)} ä¸ªm3u8é“¾æ¥:")
        for i, url in enumerate(m3u8_urls, 1):
            marker = "â­" if url == best_m3u8 else "  "
            print(f"   {marker} [{i}] {url}")
        
        print(f"\nğŸ“¥ ä½¿ç”¨ffmpegä¸‹è½½:")
        print(f'   ffmpeg -i "{best_m3u8}" -c copy output.mp4')
        
        return best_m3u8


def main():
    """ä¸»å‡½æ•°"""
    video_url = "https://www.iqiyi.com/v_1c168e2yzbk.html"
    
    parser = DirectVideoCdnParserSimple()
    final_m3u8 = parser.parse_video(video_url)
    
    if not final_m3u8:
        print("\nâŒ è§£æå¤±è´¥")
        print("\nğŸ’¡ å»ºè®®:")
        print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   2. æ£€æŸ¥APIå‚æ•°æ˜¯å¦éœ€è¦æ›´æ–°")
        print("   3. ä½¿ç”¨æµè§ˆå™¨åˆ†æè„šæœ¬è·å–æœ€æ–°çš„APIå‚æ•°")


if __name__ == '__main__':
    main()

